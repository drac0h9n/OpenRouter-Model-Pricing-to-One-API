[
  {
    "model": "deepseek/deepseek-r1-distill-llama-8b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.02,
    "output": 0.02
  },
  {
    "model": "google/gemini-2.0-flash-001",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.05,
    "output": 0.2
  },
  {
    "model": "google/gemini-2.0-flash-lite-preview-02-05:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "google/gemini-2.0-pro-exp-02-05:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "qwen/qwen-vl-plus:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "aion-labs/aion-1.0",
    "type": "tokens",
    "channel_type": 1,
    "input": 4,
    "output": 12
  },
  {
    "model": "aion-labs/aion-1.0-mini",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.4,
    "output": 1.2
  },
  {
    "model": "aion-labs/aion-rp-llama-3.1-8b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.1,
    "output": 0.1
  },
  {
    "model": "qwen/qwen-turbo",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.025,
    "output": 0.1
  },
  {
    "model": "qwen/qwen2.5-vl-72b-instruct:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "qwen/qwen-plus",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.2,
    "output": 0.6
  },
  {
    "model": "qwen/qwen-max",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.8,
    "output": 3.2
  },
  {
    "model": "openai/o3-mini",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.55,
    "output": 2.2
  },
  {
    "model": "deepseek/deepseek-r1-distill-qwen-1.5b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.09,
    "output": 0.09
  },
  {
    "model": "mistralai/mistral-small-24b-instruct-2501",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.035,
    "output": 0.07
  },
  {
    "model": "deepseek/deepseek-r1-distill-qwen-32b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.06,
    "output": 0.09
  },
  {
    "model": "deepseek/deepseek-r1-distill-qwen-14b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.075,
    "output": 0.075
  },
  {
    "model": "perplexity/sonar-reasoning",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.5,
    "output": 2.5
  },
  {
    "model": "perplexity/sonar",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.5,
    "output": 0.5
  },
  {
    "model": "liquid/lfm-7b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.005,
    "output": 0.005
  },
  {
    "model": "liquid/lfm-3b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.01,
    "output": 0.01
  },
  {
    "model": "deepseek/deepseek-r1-distill-llama-70b:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "deepseek/deepseek-r1-distill-llama-70b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.115,
    "output": 0.345
  },
  {
    "model": "google/gemini-2.0-flash-thinking-exp:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "deepseek/deepseek-r1:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "deepseek/deepseek-r1",
    "type": "tokens",
    "channel_type": 1,
    "input": 1.5,
    "output": 4
  },
  {
    "model": "sophosympatheia/rogue-rose-103b-v0.2:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "minimax/minimax-01",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.1,
    "output": 0.55
  },
  {
    "model": "mistralai/codestral-2501",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.15,
    "output": 0.45
  },
  {
    "model": "microsoft/phi-4",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.035,
    "output": 0.07
  },
  {
    "model": "sao10k/l3.1-70b-hanami-x1",
    "type": "tokens",
    "channel_type": 1,
    "input": 1.5,
    "output": 1.5
  },
  {
    "model": "deepseek/deepseek-chat:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "deepseek/deepseek-chat",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.245,
    "output": 0.445
  },
  {
    "model": "qwen/qvq-72b-preview",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.125,
    "output": 0.25
  },
  {
    "model": "google/gemini-2.0-flash-thinking-exp-1219:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "sao10k/l3.3-euryale-70b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.35,
    "output": 0.4
  },
  {
    "model": "openai/o1",
    "type": "tokens",
    "channel_type": 1,
    "input": 7.5,
    "output": 30
  },
  {
    "model": "eva-unit-01/eva-llama-3.33-70b",
    "type": "tokens",
    "channel_type": 1,
    "input": 2,
    "output": 3
  },
  {
    "model": "x-ai/grok-2-vision-1212",
    "type": "tokens",
    "channel_type": 1,
    "input": 1,
    "output": 5
  },
  {
    "model": "x-ai/grok-2-1212",
    "type": "tokens",
    "channel_type": 1,
    "input": 1,
    "output": 5
  },
  {
    "model": "cohere/command-r7b-12-2024",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.019,
    "output": 0.075
  },
  {
    "model": "google/gemini-2.0-flash-exp:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "google/gemini-exp-1206:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "meta-llama/llama-3.3-70b-instruct:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "meta-llama/llama-3.3-70b-instruct",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.06,
    "output": 0.15
  },
  {
    "model": "amazon/nova-lite-v1",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.03,
    "output": 0.12
  },
  {
    "model": "amazon/nova-micro-v1",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.018,
    "output": 0.07
  },
  {
    "model": "amazon/nova-pro-v1",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.4,
    "output": 1.6
  },
  {
    "model": "qwen/qwq-32b-preview",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.06,
    "output": 0.09
  },
  {
    "model": "google/learnlm-1.5-pro-experimental:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "eva-unit-01/eva-qwen-2.5-72b",
    "type": "tokens",
    "channel_type": 1,
    "input": 2,
    "output": 3
  },
  {
    "model": "openai/gpt-4o-2024-11-20",
    "type": "tokens",
    "channel_type": 1,
    "input": 1.25,
    "output": 5
  },
  {
    "model": "mistralai/mistral-large-2411",
    "type": "tokens",
    "channel_type": 1,
    "input": 1,
    "output": 3
  },
  {
    "model": "mistralai/mistral-large-2407",
    "type": "tokens",
    "channel_type": 1,
    "input": 1,
    "output": 3
  },
  {
    "model": "mistralai/pixtral-large-2411",
    "type": "tokens",
    "channel_type": 1,
    "input": 1,
    "output": 3
  },
  {
    "model": "x-ai/grok-vision-beta",
    "type": "tokens",
    "channel_type": 1,
    "input": 2.5,
    "output": 7.5
  },
  {
    "model": "infermatic/mn-inferor-12b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.4,
    "output": 0.6
  },
  {
    "model": "qwen/qwen-2.5-coder-32b-instruct",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.035,
    "output": 0.08
  },
  {
    "model": "raifle/sorcererlm-8x22b",
    "type": "tokens",
    "channel_type": 1,
    "input": 2.25,
    "output": 2.25
  },
  {
    "model": "eva-unit-01/eva-qwen-2.5-32b",
    "type": "tokens",
    "channel_type": 1,
    "input": 1.3,
    "output": 1.7
  },
  {
    "model": "thedrummer/unslopnemo-12b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.25,
    "output": 0.25
  },
  {
    "model": "anthropic/claude-3.5-haiku-20241022:beta",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.4,
    "output": 2
  },
  {
    "model": "anthropic/claude-3.5-haiku-20241022",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.4,
    "output": 2
  },
  {
    "model": "anthropic/claude-3.5-haiku:beta",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.4,
    "output": 2
  },
  {
    "model": "anthropic/claude-3.5-haiku",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.4,
    "output": 2
  },
  {
    "model": "neversleep/llama-3.1-lumimaid-70b",
    "type": "tokens",
    "channel_type": 1,
    "input": 1.688,
    "output": 2.25
  },
  {
    "model": "anthracite-org/magnum-v4-72b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.938,
    "output": 1.125
  },
  {
    "model": "anthropic/claude-3.5-sonnet:beta",
    "type": "tokens",
    "channel_type": 1,
    "input": 1.5,
    "output": 7.5
  },
  {
    "model": "anthropic/claude-3.5-sonnet",
    "type": "tokens",
    "channel_type": 1,
    "input": 1.5,
    "output": 7.5
  },
  {
    "model": "x-ai/grok-beta",
    "type": "tokens",
    "channel_type": 1,
    "input": 2.5,
    "output": 7.5
  },
  {
    "model": "mistralai/ministral-8b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.05,
    "output": 0.05
  },
  {
    "model": "mistralai/ministral-3b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.02,
    "output": 0.02
  },
  {
    "model": "qwen/qwen-2.5-7b-instruct",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.012,
    "output": 0.025
  },
  {
    "model": "nvidia/llama-3.1-nemotron-70b-instruct:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "nvidia/llama-3.1-nemotron-70b-instruct",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.06,
    "output": 0.15
  },
  {
    "model": "inflection/inflection-3-pi",
    "type": "tokens",
    "channel_type": 1,
    "input": 1.25,
    "output": 5
  },
  {
    "model": "inflection/inflection-3-productivity",
    "type": "tokens",
    "channel_type": 1,
    "input": 1.25,
    "output": 5
  },
  {
    "model": "google/gemini-flash-1.5-8b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.019,
    "output": 0.075
  },
  {
    "model": "anthracite-org/magnum-v2-72b",
    "type": "tokens",
    "channel_type": 1,
    "input": 1.5,
    "output": 1.5
  },
  {
    "model": "liquid/lfm-40b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.075,
    "output": 0.075
  },
  {
    "model": "thedrummer/rocinante-12b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.125,
    "output": 0.25
  },
  {
    "model": "meta-llama/llama-3.2-3b-instruct:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "meta-llama/llama-3.2-3b-instruct",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.007,
    "output": 0.012
  },
  {
    "model": "meta-llama/llama-3.2-1b-instruct:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "meta-llama/llama-3.2-1b-instruct",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.005,
    "output": 0.005
  },
  {
    "model": "meta-llama/llama-3.2-90b-vision-instruct:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "meta-llama/llama-3.2-90b-vision-instruct",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.45,
    "output": 0.45
  },
  {
    "model": "meta-llama/llama-3.2-11b-vision-instruct:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "meta-llama/llama-3.2-11b-vision-instruct",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.028,
    "output": 0.028
  },
  {
    "model": "qwen/qwen-2.5-72b-instruct",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.065,
    "output": 0.2
  },
  {
    "model": "qwen/qwen-2-vl-72b-instruct",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.2,
    "output": 0.2
  },
  {
    "model": "neversleep/llama-3.1-lumimaid-8b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.094,
    "output": 0.563
  },
  {
    "model": "openai/o1-mini-2024-09-12",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.55,
    "output": 2.2
  },
  {
    "model": "openai/o1-preview",
    "type": "tokens",
    "channel_type": 1,
    "input": 7.5,
    "output": 30
  },
  {
    "model": "openai/o1-preview-2024-09-12",
    "type": "tokens",
    "channel_type": 1,
    "input": 7.5,
    "output": 30
  },
  {
    "model": "openai/o1-mini",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.55,
    "output": 2.2
  },
  {
    "model": "mistralai/pixtral-12b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.05,
    "output": 0.05
  },
  {
    "model": "cohere/command-r-08-2024",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.071,
    "output": 0.285
  },
  {
    "model": "cohere/command-r-plus-08-2024",
    "type": "tokens",
    "channel_type": 1,
    "input": 1.188,
    "output": 4.75
  },
  {
    "model": "qwen/qwen-2-vl-7b-instruct",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.05,
    "output": 0.05
  },
  {
    "model": "sao10k/l3.1-euryale-70b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.35,
    "output": 0.4
  },
  {
    "model": "google/gemini-flash-1.5-8b-exp",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "ai21/jamba-1-5-large",
    "type": "tokens",
    "channel_type": 1,
    "input": 1,
    "output": 4
  },
  {
    "model": "ai21/jamba-1-5-mini",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.1,
    "output": 0.2
  },
  {
    "model": "microsoft/phi-3.5-mini-128k-instruct",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.05,
    "output": 0.05
  },
  {
    "model": "nousresearch/hermes-3-llama-3.1-70b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.06,
    "output": 0.15
  },
  {
    "model": "nousresearch/hermes-3-llama-3.1-405b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.4,
    "output": 0.4
  },
  {
    "model": "perplexity/llama-3.1-sonar-huge-128k-online",
    "type": "tokens",
    "channel_type": 1,
    "input": 2.5,
    "output": 2.5
  },
  {
    "model": "openai/chatgpt-4o-latest",
    "type": "tokens",
    "channel_type": 1,
    "input": 2.5,
    "output": 7.5
  },
  {
    "model": "sao10k/l3-lunaris-8b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.015,
    "output": 0.03
  },
  {
    "model": "aetherwiing/mn-starcannon-12b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.4,
    "output": 0.6
  },
  {
    "model": "openai/gpt-4o-2024-08-06",
    "type": "tokens",
    "channel_type": 1,
    "input": 1.25,
    "output": 5
  },
  {
    "model": "meta-llama/llama-3.1-405b",
    "type": "tokens",
    "channel_type": 1,
    "input": 1,
    "output": 1
  },
  {
    "model": "nothingiisreal/mn-celeste-12b",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.4,
    "output": 0.6
  },
  {
    "model": "perplexity/llama-3.1-sonar-small-128k-chat",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.1,
    "output": 0.1
  },
  {
    "model": "perplexity/llama-3.1-sonar-large-128k-chat",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.5,
    "output": 0.5
  },
  {
    "model": "perplexity/llama-3.1-sonar-large-128k-online",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.5,
    "output": 0.5
  },
  {
    "model": "perplexity/llama-3.1-sonar-small-128k-online",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.1,
    "output": 0.1
  },
  {
    "model": "meta-llama/llama-3.1-405b-instruct:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  },
  {
    "model": "meta-llama/llama-3.1-405b-instruct",
    "type": "tokens",
    "channel_type": 1,
    "input": 0.4,
    "output": 0.4
  },
  {
    "model": "meta-llama/llama-3.1-8b-instruct:free",
    "type": "tokens",
    "channel_type": 1,
    "input": 0,
    "output": 0
  }
]
